  package   org . restheart . db ;   import   com . mongodb . DBCursor ;  import   org . restheart . Bootstrapper ;  import   java . util . Arrays ;  import   java . util . Comparator ;  import   java . util . Map ;  import   java . util . Objects ;  import   java . util . Optional ;  import   java . util . TreeMap ;  import    java . util . concurrent . ExecutorService ;  import    java . util . concurrent . Executors ;  import    java . util . concurrent . TimeUnit ;  import    java . util . function . Predicate ;  import    java . util . stream . Collectors ;  import    org . restheart . cache . Cache ;  import    org . restheart . cache . CacheFactory ;  import    org . restheart . cache . LoadingCache ;  import   org . slf4j . Logger ;  import   org . slf4j . LoggerFactory ;   public class DBCursorPool  {   private static final Logger  LOGGER =  LoggerFactory . getLogger  (  DBCursorPool . class ) ;   private final  int  SKIP_SLICE_LINEAR_DELTA =   Bootstrapper . getConf  ( ) . getEagerLinearSliceDelta  ( ) ;   private final  int  SKIP_SLICE_LINEAR_WIDTH =   Bootstrapper . getConf  ( ) . getEagerLinearSliceWidht  ( ) ;   private final   int  [ ]  SKIP_SLICES_HEIGHTS =   Bootstrapper . getConf  ( ) . getEagerLinearSliceHeights  ( ) ;   private final  int  SKIP_SLICE_RND_MIN_WIDTH =   Bootstrapper . getConf  ( ) . getEagerRndSliceMinWidht  ( ) ;   private final  int  SKIP_SLICE_RND_MAX_CURSORS =   Bootstrapper . getConf  ( ) . getEagerRndMaxCursors  ( ) ;   public enum EAGER_CURSOR_ALLOCATION_POLICY  {  LINEAR ,  RANDOM ,  NONE } ;   private final  Cache  < DBCursorPoolEntryKey , DBCursor >  cache ;   private final  LoadingCache  < DBCursorPoolEntryKey , Long >  collSizes ;   private static final  long  TTL =   8 * 60 * 1000 ;   private static final  long  POOL_SIZE =   Bootstrapper . getConf  ( ) . getEagerPoolSize  ( ) ;  ExecutorService  executor =  Executors . newSingleThreadExecutor  ( ) ;   public static DBCursorPool getInstance  ( )  {  return  DBCursorPoolSingletonHolder . INSTANCE ; }   private DBCursorPool  ( )  {   cache =  CacheFactory . createLocalCache  ( POOL_SIZE ,   Cache . EXPIRE_POLICY . AFTER_READ , TTL ,   (    Map . Entry  < DBCursorPoolEntryKey ,  Optional  < DBCursor > > entry ) ->  {  if  (   entry != null &&   entry . getValue  ( ) != null )  {    entry . getValue  ( ) . ifPresent  (  v ->  v . close  ( ) ) ; } } ) ;   final CollectionDAO  collectionDAO =  new CollectionDAO  ( ) ;   collSizes =  CacheFactory . createLocalLoadingCache  ( 
<<<<<<<
100
=======
 new  CacheLoader  < DBCursorPoolEntryKey , Long >  ( )  {    @ Override public Long load  (  DBCursorPoolEntryKey key )  throws Exception  {  return  collectionDAO . getCollectionSize  (  key . getCollection  ( ) ,  key . getFilter  ( ) ) ; } }
>>>>>>>
 ,      org . restheart . cache . Cache . EXPIRE_POLICY . AFTER_WRITE ,  60 * 1000 ,   (  DBCursorPoolEntryKey key ) ->  {  return  CollectionDAO . getCollectionSize  (  key . getCollection  ( ) ,  key . getFilter  ( ) ) ; } ) ;  if  (  LOGGER . isDebugEnabled  ( ) )  {    Executors . newSingleThreadScheduledExecutor  ( ) . scheduleAtFixedRate  (   ( ) ->  {    getCacheSizes  ( ) . forEach  (   ( s , c ) ->  {   LOGGER . debug  ( "db cursor pool size: {}\t{}" , s , c ) ; } ) ;   LOGGER . trace  ( "db cursor pool entries: {}" ,   cache . asMap  ( ) . keySet  ( ) ) ; } , 1 , 1 ,  TimeUnit . MINUTES ) ; } }   public synchronized SkippedDBCursor get  (  DBCursorPoolEntryKey key ,  EAGER_CURSOR_ALLOCATION_POLICY allocationPolicy )  {  if  (   key . getSkipped  ( ) < SKIP_SLICE_LINEAR_WIDTH )  {   LOGGER . debug  ( "no cursor to reuse found with skipped {} that is less than SKIP_SLICE_WIDTH {}" ,  key . getSkipped  ( ) , SKIP_SLICE_LINEAR_WIDTH ) ;  return null ; }   Optional  < DBCursorPoolEntryKey >  _bestKey =       cache . asMap  ( ) . keySet  ( ) . stream  ( ) . filter  (  cursorsPoolFilterGt  ( key ) ) . sorted  (   Comparator . comparingInt  (  DBCursorPoolEntryKey :: getSkipped ) . reversed  ( ) ) . findFirst  ( ) ;  SkippedDBCursor  ret ;  if  (  _bestKey . isPresent  ( ) )  {   Optional  < DBCursor >  _dbcur =  cache . get  (  _bestKey . get  ( ) ) ;  if  (  _dbcur . isPresent  ( ) )  {   ret =  new SkippedDBCursor  (  _dbcur . get  ( ) ,   _bestKey . get  ( ) . getSkipped  ( ) ) ;   cache . invalidate  (  _bestKey . get  ( ) ) ;   LOGGER . debug  ( "found cursor to reuse in pool, asked with skipped {} and saving {} seeks" ,  key . getSkipped  ( ) ,   _bestKey . get  ( ) . getSkipped  ( ) ) ; } else  {   ret = null ;   LOGGER . debug  ( "no cursor to reuse found with skipped {}." ,  key . getSkipped  ( ) ) ; } } else  {   ret = null ;   LOGGER . debug  ( "no cursor to reuse found with skipped {}." ,  key . getSkipped  ( ) ) ; }   populateCache  ( key , allocationPolicy ) ;  return ret ; }   private void populateCache  (  DBCursorPoolEntryKey key ,  EAGER_CURSOR_ALLOCATION_POLICY allocationPolicy )  {  if  (  allocationPolicy ==  EAGER_CURSOR_ALLOCATION_POLICY . LINEAR )  {   populateCacheLinear  ( key ) ; } else  if  (  allocationPolicy ==  EAGER_CURSOR_ALLOCATION_POLICY . RANDOM )  {   populateCacheRandom  ( key ) ; } }   private void populateCacheLinear  (  DBCursorPoolEntryKey key )  {  if  (   key . getSkipped  ( ) < SKIP_SLICE_LINEAR_WIDTH )  {  return ; }   int  firstSlice =   key . getSkipped  ( ) / SKIP_SLICE_LINEAR_WIDTH ;   final CollectionDAO  collectionDAO =  new CollectionDAO  ( ) ;   executor . submit  (   ( ) ->  {   int  slice = firstSlice ;  for (  int tohave : SKIP_SLICES_HEIGHTS )  {   int  sliceSkips =   slice * SKIP_SLICE_LINEAR_WIDTH - SKIP_SLICE_LINEAR_DELTA ;  DBCursorPoolEntryKey  sliceKey =  new DBCursorPoolEntryKey  (  key . getCollection  ( ) ,  key . getSort  ( ) ,  key . getFilter  ( ) , sliceSkips ,  - 1 ) ;   long  existing =  getSliceHeight  ( sliceKey ) ;  for (   long  cont =  tohave - existing ;  cont > 0 ;  cont -- )  {  DBCursor  cursor =  collectionDAO . getCollectionDBCursor  (  key . getCollection  ( ) ,  key . getSort  ( ) ,  key . getFilter  ( ) ) ;   cursor . skip  ( sliceSkips ) ;  DBCursorPoolEntryKey  newkey =  new DBCursorPoolEntryKey  (  key . getCollection  ( ) ,  key . getSort  ( ) ,  key . getFilter  ( ) , sliceSkips ,  System . nanoTime  ( ) ) ;   cache . put  ( newkey , cursor ) ;   LOGGER . debug  ( "created new cursor in pool: {}" , newkey ) ; }   slice ++ ; } } ) ; }   private void populateCacheRandom  (  DBCursorPoolEntryKey key )  {   final CollectionDAO  collectionDAO =  new CollectionDAO  ( ) ;   executor . submit  (   ( ) ->  {  Long  size =   collSizes . getLoading  ( key ) . get  ( ) ;   int  sliceWidht ;   int  slices = 0 ;   int  totalSlices =    size . intValue  ( ) / SKIP_SLICE_RND_MIN_WIDTH + 1 ;  if  (  totalSlices <= SKIP_SLICE_RND_MAX_CURSORS )  {   slices = totalSlices ;   sliceWidht = SKIP_SLICE_RND_MIN_WIDTH ; } else  {   slices = SKIP_SLICE_RND_MAX_CURSORS ;   sliceWidht =   size . intValue  ( ) / slices ; }  for (   int  slice = 1 ;  slice < slices ;  slice ++ )  {   int  sliceSkips =   (  int ) slice * sliceWidht ;  DBCursorPoolEntryKey  sliceKey =  new DBCursorPoolEntryKey  (  key . getCollection  ( ) ,  key . getSort  ( ) ,  key . getFilter  ( ) , sliceSkips ,  - 1 ) ;   long  existing =  getSliceHeight  ( sliceKey ) ;  for (   long  cont =  1 - existing ;  cont > 0 ;  cont -- )  {  DBCursor  cursor =  collectionDAO . getCollectionDBCursor  (  key . getCollection  ( ) ,  key . getSort  ( ) ,  key . getFilter  ( ) ) ;   cursor . skip  ( sliceSkips ) ;  DBCursorPoolEntryKey  newkey =  new DBCursorPoolEntryKey  (  key . getCollection  ( ) ,  key . getSort  ( ) ,  key . getFilter  ( ) , sliceSkips ,  System . nanoTime  ( ) ) ;   cache . put  ( newkey , cursor ) ;   LOGGER . debug  ( "created new cursor in pool: {}" , newkey ) ; } } } ) ; }   private  long getSliceHeight  (  DBCursorPoolEntryKey key )  {   long  ret =      cache . asMap  ( ) . keySet  ( ) . stream  ( ) . filter  (  cursorsPoolFilterEq  ( key ) ) . count  ( ) ;   LOGGER . trace  ( "cursor in pool with skips {} are {}" ,  key . getSkipped  ( ) , ret ) ;  return ret ; }   private  Predicate  <  ? super DBCursorPoolEntryKey > cursorsPoolFilterEq  (  DBCursorPoolEntryKey key )  {  return  k ->      Objects . equals  (    k . getCollection  ( ) . getDB  ( ) . getName  ( ) ,    key . getCollection  ( ) . getDB  ( ) . getName  ( ) ) &&  Objects . equals  (   k . getCollection  ( ) . getName  ( ) ,   key . getCollection  ( ) . getName  ( ) ) &&  Arrays . equals  (    k . getFilter  ( ) != null ?   k . getFilter  ( ) . toArray  ( ) : null ,    key . getFilter  ( ) != null ?   key . getFilter  ( ) . toArray  ( ) : null ) &&  Arrays . equals  (    k . getSort  ( ) != null ?   k . getSort  ( ) . toArray  ( ) : null ,    key . getSort  ( ) != null ?   key . getSort  ( ) . toArray  ( ) : null ) &&   k . getSkipped  ( ) ==  key . getSkipped  ( ) ; }   private  Predicate  <  ? super DBCursorPoolEntryKey > cursorsPoolFilterGt  (  DBCursorPoolEntryKey key )  {  return  k ->      Objects . equals  (    k . getCollection  ( ) . getDB  ( ) . getName  ( ) ,    key . getCollection  ( ) . getDB  ( ) . getName  ( ) ) &&  Objects . equals  (   k . getCollection  ( ) . getName  ( ) ,   key . getCollection  ( ) . getName  ( ) ) &&  Arrays . equals  (    k . getFilter  ( ) != null ?   k . getFilter  ( ) . toArray  ( ) : null ,    key . getFilter  ( ) != null ?   key . getFilter  ( ) . toArray  ( ) : null ) &&  Arrays . equals  (    k . getSort  ( ) != null ?   k . getSort  ( ) . toArray  ( ) : null ,    key . getSort  ( ) != null ?   key . getSort  ( ) . toArray  ( ) : null ) &&   k . getSkipped  ( ) <  key . getSkipped  ( ) ; }   private  TreeMap  < String , Long > getCacheSizes  ( )  {  return  new  TreeMap  < >  (     cache . asMap  ( ) . keySet  ( ) . stream  ( ) . collect  (  Collectors . groupingBy  (  DBCursorPoolEntryKey :: getCacheStatsGroup ,  Collectors . counting  ( ) ) ) ) ; }   private static class DBCursorPoolSingletonHolder  {   private static final DBCursorPool  INSTANCE =  new DBCursorPool  ( ) ; } ; }