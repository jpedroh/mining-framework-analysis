  package    opennlp . tools . ml . perceptron ;   import   java . io . IOException ;  import    opennlp . tools . ml . AbstractEventTrainer ;  import     opennlp . tools . ml . model . AbstractModel ;  import     opennlp . tools . ml . model . DataIndexer ;  import     opennlp . tools . ml . model . EvalParameters ;  import     opennlp . tools . ml . model . MutableContext ;   public class PerceptronTrainer  extends AbstractEventTrainer  {   public static final String  PERCEPTRON_VALUE = "PERCEPTRON" ;   public static final  double  TOLERANCE_DEFAULT = .00001 ;   private  int  numUniqueEvents ;   private  int  numEvents ;   private  int  numPreds ;   private  int  numOutcomes ;   private   int  [ ] [ ]  contexts ;   private   float  [ ] [ ]  values ;   private   int  [ ]  outcomeList ;   private   int  [ ]  numTimesEventsSeen ;   private  String  [ ]  outcomeLabels ;   private  String  [ ]  predLabels ;   private boolean  printMessages = true ;   private  double  tolerance = TOLERANCE_DEFAULT ;   private Double  stepSizeDecrease ;   private boolean  useSkippedlAveraging ;   public PerceptronTrainer  ( )  { }   public boolean isValid  ( )  {  String  algorithmName =  getAlgorithm  ( ) ;  return  !  (   algorithmName != null &&  !  (  PERCEPTRON_VALUE . equals  ( algorithmName ) ) ) ; }   public boolean isSortAndMerge  ( )  {  return false ; }   public AbstractModel doTrain  (  DataIndexer indexer )  throws IOException  {  if  (  !  isValid  ( ) )  {  throw  new IllegalArgumentException  ( "trainParams are not valid!" ) ; }   int  iterations =  getIterations  ( ) ;   int  cutoff =  getCutoff  ( ) ;  AbstractModel  model ;  boolean  useAverage =  parameters . getBooleanParam  ( "UseAverage" , true ) ;  boolean  useSkippedAveraging =  parameters . getBooleanParam  ( "UseSkippedAveraging" , false ) ;  if  ( useSkippedAveraging )   useAverage = true ;   double  stepSizeDecrease =  parameters . getDoubleParam  ( "StepSizeDecrease" , 0 ) ;   double  tolerance =  parameters . getDoubleParam  ( "Tolerance" ,  PerceptronTrainer . TOLERANCE_DEFAULT ) ;   this . setSkippedAveraging  ( useSkippedAveraging ) ;  if  (  stepSizeDecrease > 0 )   this . setStepSizeDecrease  ( stepSizeDecrease ) ;   this . setTolerance  ( tolerance ) ;   model =  this . trainModel  ( iterations , indexer , cutoff , useAverage ) ;  return model ; }   public void setTolerance  (   double tolerance )  {  if  (  tolerance < 0 )  {  throw  new IllegalArgumentException  (   "tolerance must be a positive number but is " + tolerance + "!" ) ; }    this . tolerance = tolerance ; }   public void setStepSizeDecrease  (   double decrease )  {  if  (   decrease < 0 ||  decrease > 100 )  {  throw  new IllegalArgumentException  (   "decrease must be between 0 and 100 but is " + decrease + "!" ) ; }   stepSizeDecrease = decrease ; }   public void setSkippedAveraging  (  boolean averaging )  {   useSkippedlAveraging = averaging ; }   public AbstractModel trainModel  (   int iterations ,  DataIndexer di ,   int cutoff )  {  return  trainModel  ( iterations , di , cutoff , true ) ; }   public AbstractModel trainModel  (   int iterations ,  DataIndexer di ,   int cutoff ,  boolean useAverage )  {   display  ( "Incorporating indexed data for training...  \n" ) ;   contexts =  di . getContexts  ( ) ;   values =  di . getValues  ( ) ;   numTimesEventsSeen =  di . getNumTimesEventsSeen  ( ) ;   numEvents =  di . getNumEvents  ( ) ;   numUniqueEvents =  contexts . length ;   outcomeLabels =  di . getOutcomeLabels  ( ) ;   outcomeList =  di . getOutcomeList  ( ) ;   predLabels =  di . getPredLabels  ( ) ;   numPreds =  predLabels . length ;   numOutcomes =  outcomeLabels . length ;   display  ( "done.\n" ) ;   display  (   "\tNumber of Event Tokens: " + numUniqueEvents + "\n" ) ;   display  (   "\t    Number of Outcomes: " + numOutcomes + "\n" ) ;   display  (   "\t  Number of Predicates: " + numPreds + "\n" ) ;   display  ( "Computing model parameters...\n" ) ;   MutableContext  [ ]  finalParameters =  findParameters  ( iterations , useAverage ) ;   display  ( "...done.\n" ) ;  return  new PerceptronModel  ( finalParameters , predLabels , outcomeLabels ) ; }   private  MutableContext  [ ] findParameters  (   int iterations ,  boolean useAverage )  {   display  (   "Performing " + iterations + " iterations.\n" ) ;    int  [ ]  allOutcomesPattern =  new  int  [ numOutcomes ] ;  for (   int  oi = 0 ;  oi < numOutcomes ;  oi ++ )    allOutcomesPattern [ oi ] = oi ;   MutableContext  [ ]  params =  new MutableContext  [ numPreds ] ;  for (   int  pi = 0 ;  pi < numPreds ;  pi ++ )  {    params [ pi ] =  new MutableContext  ( allOutcomesPattern ,  new  double  [ numOutcomes ] ) ;  for (   int  aoi = 0 ;  aoi < numOutcomes ;  aoi ++ )    params [ pi ] . setParameter  ( aoi , 0.0 ) ; }  EvalParameters  evalParams =  new EvalParameters  ( params , numOutcomes ) ;   MutableContext  [ ]  summedParams =  new MutableContext  [ numPreds ] ;  if  ( useAverage )  {  for (   int  pi = 0 ;  pi < numPreds ;  pi ++ )  {    summedParams [ pi ] =  new MutableContext  ( allOutcomesPattern ,  new  double  [ numOutcomes ] ) ;  for (   int  aoi = 0 ;  aoi < numOutcomes ;  aoi ++ )    summedParams [ pi ] . setParameter  ( aoi , 0.0 ) ; } }   double  prevAccuracy1 = 0.0 ;   double  prevAccuracy2 = 0.0 ;   double  prevAccuracy3 = 0.0 ;   int  numTimesSummed = 0 ;   double  stepsize = 1 ;  for (   int  i = 1 ;  i <= iterations ;  i ++ )  {  if  (  stepSizeDecrease != null )   stepsize *=  1 - stepSizeDecrease ;   displayIteration  ( i ) ;   int  numCorrect = 0 ;  for (   int  ei = 0 ;  ei < numUniqueEvents ;  ei ++ )  {   int  targetOutcome =  outcomeList [ ei ] ;  for (   int  ni = 0 ;  ni <   this . numTimesEventsSeen [ ei ] ;  ni ++ )  {    double  [ ]  modelDistribution =  new  double  [ numOutcomes ] ;  if  (  values != null )   PerceptronModel . eval  (  contexts [ ei ] ,  values [ ei ] , modelDistribution , evalParams , false ) ; else   PerceptronModel . eval  (  contexts [ ei ] , null , modelDistribution , evalParams , false ) ;   int  maxOutcome =  maxIndex  ( modelDistribution ) ;  if  (  maxOutcome != targetOutcome )  {  for (   int  ci = 0 ;  ci <   contexts [ ei ] . length ;  ci ++ )  {   int  pi =   contexts [ ei ] [ ci ] ;  if  (  values == null )  {    params [ pi ] . updateParameter  ( targetOutcome , stepsize ) ;    params [ pi ] . updateParameter  ( maxOutcome ,  - stepsize ) ; } else  {    params [ pi ] . updateParameter  ( targetOutcome ,  stepsize *   values [ ei ] [ ci ] ) ;    params [ pi ] . updateParameter  ( maxOutcome ,   - stepsize *   values [ ei ] [ ci ] ) ; } } }  if  (  maxOutcome == targetOutcome )   numCorrect ++ ; } }   double  trainingAccuracy =   (  double ) numCorrect / numEvents ;  if  (   i < 10 ||   (  i % 10 ) == 0 )   display  (       ". (" + numCorrect + "/" + numEvents + ") " + trainingAccuracy + "\n" ) ;  boolean  doAveraging ;   doAveraging =    useAverage && useSkippedlAveraging &&  (   i < 20 ||  isPerfectSquare  ( i ) ) || useAverage ;  if  ( doAveraging )  {   numTimesSummed ++ ;  for (   int  pi = 0 ;  pi < numPreds ;  pi ++ )  for (   int  aoi = 0 ;  aoi < numOutcomes ;  aoi ++ )    summedParams [ pi ] . updateParameter  ( aoi ,    params [ pi ] . getParameters  ( ) [ aoi ] ) ; }  if  (     Math . abs  (  prevAccuracy1 - trainingAccuracy ) < tolerance &&   Math . abs  (  prevAccuracy2 - trainingAccuracy ) < tolerance &&   Math . abs  (  prevAccuracy3 - trainingAccuracy ) < tolerance )  {   display  (   "Stopping: change in training set accuracy less than " + tolerance + "\n" ) ;  break ; }   prevAccuracy1 = prevAccuracy2 ;   prevAccuracy2 = prevAccuracy3 ;   prevAccuracy3 = trainingAccuracy ; }   trainingStats  ( evalParams ) ;  if  ( useAverage )  {  for (   int  pi = 0 ;  pi < numPreds ;  pi ++ )  for (   int  aoi = 0 ;  aoi < numOutcomes ;  aoi ++ )    summedParams [ pi ] . setParameter  ( aoi ,     summedParams [ pi ] . getParameters  ( ) [ aoi ] / numTimesSummed ) ;  return summedParams ; } else  {  return params ; } }   private  double trainingStats  (  EvalParameters evalParams )  {   int  numCorrect = 0 ;  for (   int  ei = 0 ;  ei < numUniqueEvents ;  ei ++ )  {  for (   int  ni = 0 ;  ni <   this . numTimesEventsSeen [ ei ] ;  ni ++ )  {    double  [ ]  modelDistribution =  new  double  [ numOutcomes ] ;  if  (  values != null )   PerceptronModel . eval  (  contexts [ ei ] ,  values [ ei ] , modelDistribution , evalParams , false ) ; else   PerceptronModel . eval  (  contexts [ ei ] , null , modelDistribution , evalParams , false ) ;   int  max =  maxIndex  ( modelDistribution ) ;  if  (  max ==  outcomeList [ ei ] )   numCorrect ++ ; } }   double  trainingAccuracy =   (  double ) numCorrect / numEvents ;   display  (       "Stats: (" + numCorrect + "/" + numEvents + ") " + trainingAccuracy + "\n" ) ;  return trainingAccuracy ; }   private  int maxIndex  (    double  [ ] values )  {   int  max = 0 ;  for (   int  i = 1 ;  i <  values . length ;  i ++ )  if  (   values [ i ] >  values [ max ] )   max = i ;  return max ; }   private void display  (  String s )  {  if  ( printMessages )    System . out . print  ( s ) ; }   private void displayIteration  (   int i )  {  if  (   i > 10 &&   (  i % 10 ) != 0 )  return ;  if  (  i < 10 )   display  (   "  " + i + ":  " ) ; else  if  (  i < 100 )   display  (   " " + i + ":  " ) ; else   display  (  i + ":  " ) ; }   private static boolean isPerfectSquare  (   int n )  {   int  root =  (  int )  Math . sqrt  ( n ) ;  return   root * root == n ; } }